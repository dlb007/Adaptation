{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Start by setting up your content import. You can use the same target content as you used for exercise two, or set up something new. \r\n",
    "# Read in and store the content from a single URL.\r\n",
    "\r\n",
    "import urllib.request, urllib.error, urllib.parse\r\n",
    "\r\n",
    "url = 'https://www.hollywoodreporter.com/movies/movie-news/afm-hidden-gem-how-pandemic-set-rom-com-mycorona-was-directed-entirely-remotely-4091223/#!'\r\n",
    "\r\n",
    "response = urllib.request.urlopen(url)\r\n",
    "webContents = response.read()\r\n",
    "\r\n",
    "print(webContents[0:1000])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b'<!DOCTYPE html>\\n<!--[if IE 6]>\\n<html id=\"ie6\" lang=\"en-US\">\\n<![endif]-->\\n<!--[if IE 7]>\\n<html id=\"ie7\" lang=\"en-US\">\\n<![endif]-->\\n<!--[if IE 8]>\\n<html id=\"ie8\" lang=\"en-US\">\\n<![endif]-->\\n<!--[if !(IE 6) | !(IE 7) | !(IE 8) ]><!-->\\n<html lang=\"en-US\">\\n<!--<![endif]-->\\n<head>\\n\\t<meta charset=\"UTF-8\"/>\\n\\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\\n\\t<meta name=\"theme-color\" content=\"#ffffff\">\\n\\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"/>\\n\\t<!-- Favicons -->\\n<link rel=\"icon\" type=\"image/png\" href=\"https://www.hollywoodreporter.com/wp-content/themes/vip/pmc-hollywoodreporter-2021/assets/app/icons/favicon.png\">\\n<link rel=\"shortcut icon\" href=\"https://www.hollywoodreporter.com/wp-content/themes/vip/pmc-hollywoodreporter-2021/assets/app/icons/favicon.ico\">\\n\\t\\n<!--\\n\\t\\t _     _ _           ____          _          _____ _    ___\\n\\t\\t| |   (_) | _____   / ___|___   __| | ___    | ____| |__|__ \\\\\\n\\t\\t| |   | | |/ / _ \\\\ | |   / _ \\\\ / _` |/ _ \\\\   |  _| | \\'_ \\\\ / /\\n\\t'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Next, splice the content you've imported to include only the primary text of interest. \r\n",
    "# You'll need to investigate the website you are looking at and choose strategically what tags you look for to define the starting and ending location of your splice. \r\n",
    "# Build on the model in CleaningHTML.ipynb\r\n",
    "\r\n",
    "contents = str(webContents)\r\n",
    "startLoc = contents.find(\"class=\\\"wf-keplerstd)\r\n",
    "endLoc = contents.find(\".\\\"/>\")\r\n",
    "\r\n",
    "print(startLoc)\r\n",
    "print(endLoc)\r\n",
    "\r\n",
    "contents = contents[startLoc: endLoc]\r\n",
    "print(contents[0: 500])\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-9-1003435fc01e>, line 6)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-1003435fc01e>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    startLoc = contents.find(\"class=\\\"wf-keplerstd)\u001b[0m\n\u001b[1;37m                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Implement a loop to remove all the HTML tags from your text. Use the model provided in CleaningHTML.ipynb, and make sure to store your cleaned text as a string. \r\n",
    "# Print the string and inspect the results. Save your now  cleaned text as a .txt file with an appropriate name.\r\n",
    "\r\n",
    "inside = 0\r\n",
    "text = ''\r\n",
    "\r\n",
    "for char in contents:\r\n",
    "    if char == '<':\r\n",
    "        inside = 1\r\n",
    "    elif (inside == 1 and char == '>'):\r\n",
    "        inside = 0\r\n",
    "    elif inside== 1:\r\n",
    "        continue\r\n",
    "    else: \r\n",
    "        text += char\r\n",
    "\r\n",
    "text = text.replace(\"\\\\n\",\"\")\r\n",
    "text = text.replace(\"\\\\r\",\"\")\r\n",
    "print(text[0: 500])\r\n",
    "\r\n",
    "f = open('chairreviews.txt','w')\r\n",
    "f.write(text)\r\n",
    "f.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "content=\"This guide is an introduction to the resources for Film Studies at Dartmouth.  If you are interested in Television, see the separate research guide for Television\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# As your bonus challenge for this week, identify at least one other area of content that needs cleaning from your file: \r\n",
    "# this might be URLs, {} content, special characters, or other \"noise\" you want to cut from your spring. \r\n",
    "# Using a combination of loops, conditionals, and string methods as appropriate, remove those elements from the text.\r\n",
    "\r\n",
    "inside = 0\r\n",
    "text = ''\r\n",
    "\r\n",
    "for char in contents:\r\n",
    "    if char == '<':\r\n",
    "        inside = 1\r\n",
    "    elif (inside == 1 and char == '>'):\r\n",
    "        inside = 0\r\n",
    "    elif inside== 1:\r\n",
    "        continue\r\n",
    "    else: \r\n",
    "        text += char\r\n",
    "\r\n",
    "print(text[0: 500])\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " content=\"This guide is an introduction to the resources for Film Studies at Dartmouth.  If you are interested in Television, see the separate research guide for Television\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Now we're ready to analyze our text. This time, try combining the elements we've used so far to handle our text by writing a simple algorithm following this model:\r\n",
    "\r\n",
    "# First, split your string into a \"bag of words\" by cutting at the whitespace into an array.\r\n",
    "\r\n",
    "text = text.lower()\r\n",
    "wordBag = text.split()\r\n",
    "\r\n",
    "\r\n",
    "# Next, create a loop that runs through every word in your new array\r\n",
    "# Within the loop, create some conditionals and behaviors to process the words. \r\n",
    "# For instance, you might print out every word that starts with a certain letter, or print out words longer than a set length, etc. \r\n",
    "# Try playing with the loop breaks and continue options to handle different types of words differently.\r\n",
    "\r\n",
    "for word in wordBag:\r\n",
    "    if word == \"pious\":\r\n",
    "        print(\"The reviewer has brought piety into this.\")\r\n",
    "    elif word == \"gender\" or word == \"race\":\r\n",
    "        print(\"The reviewer has acknowledged \" + word)\r\n",
    "    #note that gender doesn't work (in this dataset the punctuation interferes - we'll fix this next week!)\r\n",
    "    elif len(word) > 10:\r\n",
    "        print(word)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "content=\"this\n",
      "introduction\n",
      "television,\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "interpreter": {
   "hash": "598d64e08a06bfba065a99698ec5bbec753236817de80e4f3bcf221574aa140c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}